{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8019084,"sourceType":"datasetVersion","datasetId":2729190},{"sourceId":10125741,"sourceType":"datasetVersion","datasetId":6248485},{"sourceId":10126151,"sourceType":"datasetVersion","datasetId":6248800},{"sourceId":10126230,"sourceType":"datasetVersion","datasetId":6248862},{"sourceId":10126262,"sourceType":"datasetVersion","datasetId":6248888},{"sourceId":10126616,"sourceType":"datasetVersion","datasetId":6249162},{"sourceId":10127422,"sourceType":"datasetVersion","datasetId":6249770},{"sourceId":10127933,"sourceType":"datasetVersion","datasetId":6250153}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\nimport timm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:36:34.235808Z","iopub.execute_input":"2024-12-08T10:36:34.236368Z","iopub.status.idle":"2024-12-08T10:36:40.032831Z","shell.execute_reply.started":"2024-12-08T10:36:34.236341Z","shell.execute_reply":"2024-12-08T10:36:40.032136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Dataset","metadata":{}},{"cell_type":"code","source":"# input folder\nfrom pathlib import Path\nPath('/kaggle/working/oral-diseases/').mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:36:49.941423Z","iopub.execute_input":"2024-12-08T10:36:49.942169Z","iopub.status.idle":"2024-12-08T10:36:49.946078Z","shell.execute_reply.started":"2024-12-08T10:36:49.942140Z","shell.execute_reply":"2024-12-08T10:36:49.945274Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Augment Data","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom PIL import Image\nfrom torchvision import transforms\nfrom tqdm import tqdm\n\n# Paths\ninput_dir = '/kaggle/input/new-dataset-oral/archive (1)/Healthy Teeth/Healthy Teeth'  # Path to the folder containing \"healthy teeth\" images\noutput_dir = '/kaggle/working/augmented-teeth_new'  # Path where augmented images will be saved\nnum_augmented_images = 500  # Total number of augmented images to generate\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Define the image transformations (data augmentation)\ntransform = transforms.Compose([\n    # transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n    transforms.RandomRotation(degrees=30),  # Random rotation\n    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),  # Random crop and resize\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n    # transforms.RandomVerticalFlip(p=0.2),  # Random vertical flip\n    transforms.ToTensor(),  # Convert to tensor\n    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n    transforms.ToPILImage()  # Convert back to PIL image for saving\n])\n\n# Get list of all images in the \"healthy teeth\" folder\nimage_paths = [os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith(('jpg', 'jpeg', 'png'))]\n\n# Generate augmented images\nprint(f\"Found {len(image_paths)} images in '{input_dir}'. Generating {num_augmented_images} augmented images...\")\n\nfor i in tqdm(range(num_augmented_images), desc=\"Augmenting Images\"):\n    # Randomly select an image from the input folder\n    img_path = random.choice(image_paths)\n    \n    # Open image and apply transformations\n    image = Image.open(img_path).convert('RGB')  # Ensure image is RGB\n    augmented_image = transform(image)\n    \n    # Save the augmented image, starting from 201\n    output_path = os.path.join(output_dir, f\"augmented_image_{i + 201}.jpg\")\n    augmented_image.save(output_path)\n\nprint(f\"Successfully created {num_augmented_images} augmented images in '{output_dir}' starting from 201.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:36:50.715497Z","iopub.execute_input":"2024-12-08T10:36:50.715788Z","iopub.status.idle":"2024-12-08T10:36:57.558470Z","shell.execute_reply.started":"2024-12-08T10:36:50.715766Z","shell.execute_reply":"2024-12-08T10:36:57.557615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Caries.\n# The source path\ncaries_file_path = Path('/kaggle/input/oral-diseases/Data caries/Data caries/caries augmented data set/preview')\n\n# The destination path\ncaries_new_directory = Path('/kaggle/working/oral-diseases/caries')\n\n# Copying data from input folder to working folder\nshutil.copytree(caries_file_path, caries_new_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:36:58.582249Z","iopub.execute_input":"2024-12-08T10:36:58.582569Z","iopub.status.idle":"2024-12-08T10:37:12.125582Z","shell.execute_reply.started":"2024-12-08T10:36:58.582545Z","shell.execute_reply":"2024-12-08T10:37:12.124769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculus\n# The source path\ncalculus_file_path = Path('/kaggle/input/oral-diseases/Calculus/Calculus')\n# The destination path\ncalculus_new_directory = Path('/kaggle/working/oral-diseases/calculus')\n# Copying data from input folder to working folder\nshutil.copytree(calculus_file_path, calculus_new_directory)\n\n#Gingivitis\n# The source path\ngingivitis_file_path = Path('/kaggle/input/oral-diseases/Gingivitis/Gingivitis')\n# The destination path\ngingivitis_new_directory = Path('/kaggle/working/oral-diseases/gingivitis')\n# Copying data from input folder to working folder\nshutil.copytree(gingivitis_file_path, gingivitis_new_directory)\n\n#Ulcers\n# The source path\nulcer_file_path = Path('/kaggle/input/oral-diseases/Mouth Ulcer/Mouth Ulcer/Mouth_Ulcer_augmented_DataSet/preview')\n# The destination path\nulcer_new_directory = Path('/kaggle/working/oral-diseases/ulcers')\n# Copying data from input folder to working folder\nshutil.copytree(ulcer_file_path, ulcer_new_directory)\n\n#Tooth Discoloration\n# The source path\ntoothDiscoloration_file_path = Path('/kaggle/input/oral-diseases/Tooth Discoloration/Tooth Discoloration /Tooth_discoloration_augmented_dataser/preview')\n# The destination path\ntoothDiscoloration_new_directory = Path('/kaggle/working/oral-diseases/toothDiscoloration')\n# Copying data from input folder to working folder\nshutil.copytree(toothDiscoloration_file_path, toothDiscoloration_new_directory)\n\n#hypodontia\n# The source path\nhypodontia_file_path = Path('/kaggle/input/oral-diseases/hypodontia/hypodontia')\n# The destination path\nhypodontia_new_directory = Path('/kaggle/working/oral-diseases/hypodontia')\n# Copying data from input folder to working folder\nshutil.copytree(hypodontia_file_path, hypodontia_new_directory)\n\nHealthy_Teeth_file_path = Path('/kaggle/input/new-dataset-oral/archive (1)/Healthy Teeth/Healthy Teeth')\n# The destination path\nHealthy_Teeth_new_directory = Path('/kaggle/input/new-dataset-oral/archive (1)/Healthy Teeth/Healthy Teeth')\n# Copying data from input folder to working folder\nshutil.copytree(Healthy_Teeth_file_path, hypodontia_new_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:37:12.126831Z","iopub.execute_input":"2024-12-08T10:37:12.127111Z","iopub.status.idle":"2024-12-08T10:38:05.017757Z","shell.execute_reply.started":"2024-12-08T10:37:12.127089Z","shell.execute_reply":"2024-12-08T10:38:05.016416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Healthy_Teeth_file_path = Path('/kaggle/working/augmented-teeth_new')\n# The destination path\nHealthy_Teeth_new_directory = Path('/kaggle/working/oral-diseases/healthy_teeth')\n# Copying data from input folder to working folder\nshutil.copytree(Healthy_Teeth_file_path, Healthy_Teeth_new_directory)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:38:30.334154Z","iopub.execute_input":"2024-12-08T10:38:30.334496Z","iopub.status.idle":"2024-12-08T10:38:30.392692Z","shell.execute_reply.started":"2024-12-08T10:38:30.334468Z","shell.execute_reply":"2024-12-08T10:38:30.391932Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Data","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Paths to the oral disease categories\ndisease_paths = {\n    'Caries': '/kaggle/working/oral-diseases/caries',\n    'Calculus': '/kaggle/working/oral-diseases/calculus',\n    'Gingivitis': '/kaggle/working/oral-diseases/gingivitis',\n    'Ulcers': '/kaggle/working/oral-diseases/ulcers',\n    'Tooth Discoloration': '/kaggle/working/oral-diseases/toothDiscoloration',\n    'Hypodontia': '/kaggle/working/oral-diseases/hypodontia',\n    'Healthy Teeth': '/kaggle/working/oral-diseases/healthy_teeth'\n}\n\n# Function to get a random unique image from each class\ndef get_unique_images_from_each_class(disease_paths, num_images=9):\n    \"\"\"\n    Get unique images from each disease class. \n    If there are not enough unique classes, duplicate random images from existing categories.\n    \"\"\"\n    images_with_labels = []\n    for label, path in disease_paths.items():\n        image_files = [os.path.join(path, fname) for fname in os.listdir(path) if fname.endswith(('jpg', 'jpeg', 'png'))]\n        if image_files:\n            # Select a unique image from the class\n            random_image = random.choice(image_files)\n            images_with_labels.append((random_image, label))\n    \n    # If not enough unique classes, randomly select additional images\n    while len(images_with_labels) < num_images:\n        label, path = random.choice(list(disease_paths.items()))\n        image_files = [os.path.join(path, fname) for fname in os.listdir(path) if fname.endswith(('jpg', 'jpeg', 'png'))]\n        if image_files:\n            random_image = random.choice(image_files)\n            if random_image not in [img[0] for img in images_with_labels]:  # Ensure no duplicate images\n                images_with_labels.append((random_image, label))\n    \n    return images_with_labels[:num_images]  # Return exactly 9 images\n\n# Get 9 unique images from each class\nimages_with_labels = get_unique_images_from_each_class(disease_paths, num_images=9)\n\n# Resize dimensions (all images will be resized to this size)\nresize_dim = (224, 224)  # (width, height)\n\n# Customization of the plot size and resolution\nplot_width = 15  # Width of the entire plot (in inches)\nplot_height = 10  # Height of the entire plot (in inches)\ndpi = 150  # Resolution of the image (higher dpi = higher quality)\n\n# Create a 3x3 grid\nfig, axes = plt.subplots(3, 3, figsize=(plot_width, plot_height), dpi=dpi)\nfig.suptitle('Oral Disease Classification - Sample Images', fontsize=24, fontweight='bold')\n\nfor i, (img_path, label) in enumerate(images_with_labels):\n    row, col = divmod(i, 3)  # Determine the row and column for the grid\n    image = Image.open(img_path).convert(\"RGB\")\n    image = image.resize(resize_dim)  # Resize image to (224x224)\n    \n    axes[row, col].imshow(image)\n    axes[row, col].set_title(label, fontsize=18, fontweight='bold')\n    axes[row, col].axis('off')  # Hide axes\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.93)  # Adjust to make space for the title\n\n# Save the figure as an image\noutput_path = '/kaggle/working/oral_disease_grid.jpg'\nplt.savefig(output_path, bbox_inches='tight')\nplt.show()\n\nprint(f\"Successfully saved the 3x3 grid as an image at {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# The different classes we have from the folders\nimport os\nbuild_dir = \"/kaggle/working/oral-diseases\"\ncaries_dir = os.path.join(build_dir,'caries')\ngingivitis_dir = os.path.join(build_dir,'gingivitis')\ntoothDiscoloration_dir = os.path.join(build_dir,'toothDiscoloration')\nulcers_dir = os.path.join(build_dir,'ulcers')\nhypodontia_dir = os.path.join(build_dir,'hypodontia')\ncalculus_dir = os.path.join(build_dir,'calculus')\nhealthy_dir=os.path.join(build_dir,'healthy_teeth')\nos.listdir(build_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Showing the total number of images from each class/folder\nimport pandas as pd\n\ndata = pd.DataFrame(data=[len(os.listdir(caries_dir)), len(os.listdir(gingivitis_dir)),\n                   len(os.listdir(toothDiscoloration_dir)), len(os.listdir(ulcers_dir)),\n                   len(os.listdir(hypodontia_dir)),\n                   len(os.listdir(calculus_dir))], index=['Caries', 'Gingivitis',\n                                                                    'toothDiscoloration', 'ulcers',\n                                                                    'hypodontia', 'calculus'],\n              columns=['Total Images'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.to_csv('data_distribution.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Data Loader","metadata":{}},{"cell_type":"code","source":"# Custom Dataset class\nclass OralDiseaseDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = os.listdir(root_dir)\n        self.data = []\n        for cls in self.classes:\n            path = os.path.join(root_dir, cls)\n            for img_name in os.listdir(path):\n                self.data.append((os.path.join(path, img_name), self.classes.index(cls)))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:38:41.082627Z","iopub.execute_input":"2024-12-08T10:38:41.083071Z","iopub.status.idle":"2024-12-08T10:38:41.089446Z","shell.execute_reply.started":"2024-12-08T10:38:41.083041Z","shell.execute_reply":"2024-12-08T10:38:41.088508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\n# Custom Dataset class\nclass OralDiseaseDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = os.listdir(root_dir)\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}  # Mapping of class names to indices\n        self.data = []\n\n        # Collect all images with their paths and labels\n        for cls in self.classes:\n            class_path = os.path.join(root_dir, cls)\n            for img_name in os.listdir(class_path):\n                img_path = os.path.join(class_path, img_name)\n                label = self.class_to_idx[cls]\n                self.data.append({'path': img_path, 'label': label, 'class_name': cls})\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_info = self.data[idx]\n        img_path, label = img_info['path'], img_info['label']\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n    def get_data_info(self):\n        \"\"\"Returns a list of tuples with image path, label index, and class name.\"\"\"\n        return [(item['path'], item['label'], item['class_name']) for item in self.data]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create dataset instance\ndataset = OralDiseaseDataset(root_dir=\"/kaggle/working/oral-diseases\")\n\n# Retrieve and print image paths and labels\ndata_info = dataset.get_data_info()\nfor path, label, class_name in data_info:\n    print(f\"Image Path: {path}, Label Index: {label}, Class Name: {class_name}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"# InceptionResNetV2 Model\nclass InceptionResNetV2(nn.Module):\n    def __init__(self, num_classes):\n        super(InceptionResNetV2, self).__init__()\n        self.model = timm.create_model('inception_resnet_v2', pretrained=True)\n        in_features = self.model.classif.in_features  # Get the number of features in last layer\n        self.model.classif = nn.Linear(in_features, num_classes)  # Replace last layer\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import timm\nimport torch.nn as nn\n\nclass LightweightModel(nn.Module):\n    def __init__(self, model_name, num_classes):\n        \"\"\"\n        Initialize a lightweight model using timm.\n        \n        Args:\n            model_name (str): The name of the model to be used from timm.\n            num_classes (int): The number of output classes.\n        \"\"\"\n        super(LightweightModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=True)\n        \n        # Handle different model architectures (classifier vs. fc layers)\n        if hasattr(self.model, 'classifier'):  # For models like EfficientNet, MobileNet\n            in_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(in_features, num_classes)\n        elif hasattr(self.model, 'fc'):  # For models like ResNet\n            in_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(in_features, num_classes)\n        else:\n            raise ValueError(\"Unexpected model architecture. Check the model's last layer.\")\n\n    def forward(self, x):\n        return self.model(x)\n\n\n# Usage Example\nif __name__ == \"__main__\":\n    model_name = 'resnet18'  # Options: 'mobilenetv2_100', 'efficientnet_lite0', 'resnet18', etc.\n    num_classes = 5  # Number of classes\n    model = LightweightModel(model_name, num_classes)\n    print(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:38:46.504695Z","iopub.execute_input":"2024-12-08T10:38:46.505526Z","iopub.status.idle":"2024-12-08T10:38:47.170451Z","shell.execute_reply.started":"2024-12-08T10:38:46.505494Z","shell.execute_reply":"2024-12-08T10:38:47.169627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import timm\nimport torch.nn as nn\n\n# Lightweight Model: MobileNetV2\nclass MobileNetV2(nn.Module):\n    def __init__(self, num_classes):\n        super(MobileNetV2, self).__init__()\n        self.model = timm.create_model('mobilenetv2_100', pretrained=True)\n        in_features = self.model.classifier.in_features  # Get the number of features in the last layer\n        self.model.classifier = nn.Linear(in_features, num_classes)  # Replace the last layer\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EarlyStopping class\nclass EarlyStopping:\n    def __init__(self, patience=5, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n        elif val_loss > self.best_loss + self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        ''' Save model when validation loss decrease. '''\n        torch.save(model.state_dict(), 'checkpoint.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:39:27.126246Z","iopub.execute_input":"2024-12-08T10:39:27.126575Z","iopub.status.idle":"2024-12-08T10:39:27.133531Z","shell.execute_reply.started":"2024-12-08T10:39:27.126549Z","shell.execute_reply":"2024-12-08T10:39:27.132584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Initialize Model","metadata":{}},{"cell_type":"code","source":"# Parameters\nnum_classes = 7  # Update with the number of classes\nbatch_size = 32\nnum_epochs = 10\nlearning_rate = 0.001\nroot_dir = \"/kaggle/working/oral-diseases\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:39:28.826144Z","iopub.execute_input":"2024-12-08T10:39:28.826469Z","iopub.status.idle":"2024-12-08T10:39:28.830859Z","shell.execute_reply.started":"2024-12-08T10:39:28.826443Z","shell.execute_reply":"2024-12-08T10:39:28.829913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    model_name = 'resnet18'  # Options: 'mobilenetv2_100', 'efficientnet_lite0', 'resnet18', etc.\n    num_classes = 7  # Number of classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:39:51.766946Z","iopub.execute_input":"2024-12-08T10:39:51.767302Z","iopub.status.idle":"2024-12-08T10:39:52.197109Z","shell.execute_reply.started":"2024-12-08T10:39:51.767276Z","shell.execute_reply":"2024-12-08T10:39:52.195835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model, Loss and Optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LightweightModel(model_name, num_classes).to(device)\n# model = MobileNetV2(num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Learning Rate Scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n# Early Stopping\nearly_stopper = EarlyStopping(patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:40:17.159284Z","iopub.execute_input":"2024-12-08T10:40:17.159625Z","iopub.status.idle":"2024-12-08T10:40:17.589253Z","shell.execute_reply.started":"2024-12-08T10:40:17.159596Z","shell.execute_reply":"2024-12-08T10:40:17.588572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:40:07.835666Z","iopub.execute_input":"2024-12-08T10:40:07.836136Z","iopub.status.idle":"2024-12-08T10:40:07.842756Z","shell.execute_reply.started":"2024-12-08T10:40:07.836098Z","shell.execute_reply":"2024-12-08T10:40:07.841734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation and normalization for training\ntrain_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((299, 299)),  # Inception models expect 299x299 inputs\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n#     torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Normalization for testing\ntest_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((299, 299)),\n    torchvision.transforms.ToTensor(),\n#     torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Initialize dataset\ndataset = OralDiseaseDataset(root_dir, transform=train_transforms)\n\n# Splitting the dataset into train and test\ntrain_size = int(0.9 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\ntest_dataset.dataset.transform = test_transforms\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:40:08.857639Z","iopub.execute_input":"2024-12-08T10:40:08.858545Z","iopub.status.idle":"2024-12-08T10:40:08.892390Z","shell.execute_reply.started":"2024-12-08T10:40:08.858511Z","shell.execute_reply":"2024-12-08T10:40:08.891170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the class labels\nclass_labels = test_dataset.classes\n\nprint(\"Class labels:\")\nfor index, label in enumerate(class_labels):\n    print(f\"Index: {index}, Label: {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:40:10.542025Z","iopub.execute_input":"2024-12-08T10:40:10.542384Z","iopub.status.idle":"2024-12-08T10:40:10.569023Z","shell.execute_reply.started":"2024-12-08T10:40:10.542354Z","shell.execute_reply":"2024-12-08T10:40:10.567658Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Resnet18","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch + 1}/{num_epochs}')\n    \n    # Training Phase\n    model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_correct += (predicted == labels).sum().item()\n        train_total += labels.size(0)\n\n    train_accuracy = train_correct / train_total\n    train_losses.append(train_loss / len(train_loader))\n    train_accuracies.append(train_accuracy)\n\n    # Validation Phase\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Validating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_accuracy = val_correct / val_total\n    val_losses.append(val_loss / len(test_loader))\n    val_accuracies.append(val_accuracy)\n\n    print(f'Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.4f}')\n\n    scheduler.step()\n\n    early_stopper(val_losses[-1], model)\n    if early_stopper.early_stop:\n        print(\"Early stopping triggered\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T10:40:31.203577Z","iopub.execute_input":"2024-12-08T10:40:31.204599Z","iopub.status.idle":"2024-12-08T10:53:30.953359Z","shell.execute_reply.started":"2024-12-08T10:40:31.204557Z","shell.execute_reply":"2024-12-08T10:53:30.952452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Efficientnet_lite0","metadata":{}},{"cell_type":"code","source":"# Model, Loss and Optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LightweightModel('efficientnet_lite0', num_classes).to(device)\n# model = MobileNetV2(num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n# Learning Rate Scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n# Early Stopping\nearly_stopper = EarlyStopping(patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:13:27.724507Z","iopub.execute_input":"2024-12-08T11:13:27.724822Z","iopub.status.idle":"2024-12-08T11:13:29.146590Z","shell.execute_reply.started":"2024-12-08T11:13:27.724798Z","shell.execute_reply":"2024-12-08T11:13:29.145668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch + 1}/{num_epochs}')\n    \n    # Training Phase\n    model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_correct += (predicted == labels).sum().item()\n        train_total += labels.size(0)\n\n    train_accuracy = train_correct / train_total\n    train_losses.append(train_loss / len(train_loader))\n    train_accuracies.append(train_accuracy)\n\n    # Validation Phase\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Validating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_accuracy = val_correct / val_total\n    val_losses.append(val_loss / len(test_loader))\n    val_accuracies.append(val_accuracy)\n\n    print(f'Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.4f}')\n\n    scheduler.step()\n\n    early_stopper(val_losses[-1], model)\n    if early_stopper.early_stop:\n        print(\"Early stopping triggered\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:13:36.430962Z","iopub.execute_input":"2024-12-08T11:13:36.431292Z","iopub.status.idle":"2024-12-08T11:26:01.130510Z","shell.execute_reply.started":"2024-12-08T11:13:36.431265Z","shell.execute_reply":"2024-12-08T11:26:01.129585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train MobilenetV2_lite","metadata":{}},{"cell_type":"code","source":"# Model, Loss and Optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LightweightModel('mobilenetv2_100', num_classes).to(device)\n# model = MobileNetV2(num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Learning Rate Scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n# Early Stopping\nearly_stopper = EarlyStopping(patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:46:15.513023Z","iopub.execute_input":"2024-12-08T11:46:15.513344Z","iopub.status.idle":"2024-12-08T11:46:15.856316Z","shell.execute_reply.started":"2024-12-08T11:46:15.513321Z","shell.execute_reply":"2024-12-08T11:46:15.855651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch + 1}/{num_epochs}')\n    \n    # Training Phase\n    model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_correct += (predicted == labels).sum().item()\n        train_total += labels.size(0)\n\n    train_accuracy = train_correct / train_total\n    train_losses.append(train_loss / len(train_loader))\n    train_accuracies.append(train_accuracy)\n\n    # Validation Phase\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Validating\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_accuracy = val_correct / val_total\n    val_losses.append(val_loss / len(test_loader))\n    val_accuracies.append(val_accuracy)\n\n    print(f'Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.4f}')\n\n    scheduler.step()\n\n    early_stopper(val_losses[-1], model)\n    if early_stopper.early_stop:\n        print(\"Early stopping triggered\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T11:46:24.305370Z","iopub.execute_input":"2024-12-08T11:46:24.305706Z","iopub.status.idle":"2024-12-08T12:02:00.317711Z","shell.execute_reply.started":"2024-12-08T11:46:24.305678Z","shell.execute_reply":"2024-12-08T12:02:00.316884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convert to tflite","metadata":{}},{"cell_type":"code","source":"\n# Define a dummy input with the same shape as your model's input\ndummy_input = torch.randn(1, 3, 299, 299).to(device)  # Adjust shape if different\n\n# Export the model to ONNX format\nonnx_path = \"model.onnx\"\ntorch.onnx.export(model, dummy_input, onnx_path, export_params=True, opset_version=11, \n                  do_constant_folding=True, input_names=['input'], output_names=['output'])\nprint(\"Model exported to ONNX format.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install onnx-tf tensorflow\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import onnx\nfrom onnx_tf.backend import prepare\n\n# Load the ONNX model\nonnx_model = onnx.load(onnx_path)\ntf_rep = prepare(onnx_model)  # Convert ONNX model to TensorFlow format\n\n# Save as TensorFlow SavedModel\nsaved_model_dir = \"saved_model\"\ntf_rep.export_graph(saved_model_dir)\nprint(\"Model saved as TensorFlow SavedModel.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Convert SavedModel to TFLite\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\ntflite_model = converter.convert()\n\n# Save the TFLite model\nwith open(\"model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\nprint(\"Model converted and saved as TFLite.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install onnxruntime\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import onnxruntime as ort\nimport numpy as np\n\n# Load ONNX model\nonnx_session = ort.InferenceSession(\"model.onnx\")\n\n# Prepare a sample input matching the expected input size, e.g., (1, 3, 299, 299)\ndummy_input = np.random.rand(1, 3, 299, 299).astype(np.float32)\n\n# Run inference\noutputs = onnx_session.run(None, {\"input\": dummy_input})\n\n# Check output\nprint(\"ONNX output:\", outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\n# Load TFLite model\ninterpreter = tf.lite.Interpreter(model_path=\"/kaggle/input/model-test/model.tflite\")\ninterpreter.allocate_tensors()\n\n# Get input and output details\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Prepare a sample input\ndummy_input = np.random.rand(1, 3, 299, 299).astype(np.float32)  # Match the expected shape\n\n# Set input tensor\ninterpreter.set_tensor(input_details[0]['index'], dummy_input)\n\n# Run inference\ninterpreter.invoke()\n\n# Get output\noutput = interpreter.get_tensor(output_details[0]['index'])\nprint(\"TFLite output:\", output)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Model","metadata":{}},{"cell_type":"code","source":"labels=['ca','td','ht','car','ul','gi','hp']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport io\n\n# Load and preprocess the image from URL\ndef preprocess_image_from_url(image_url, target_size):\n    # Fetch the image from the URL\n    response = requests.get(image_url)\n    img = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n    # Resize the image\n    img = img.resize(target_size)\n    # Convert to a numpy array with FLOAT32 type and scale to [0, 1]\n    img_array = np.array(img).astype(np.float32) / 255.0\n    # Reorder dimensions to [batch, channels, height, width]\n    img_array = np.transpose(img_array, (2, 0, 1))  # Convert to [3, 299, 299]\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    return img, img_array  # Return both the original image and preprocessed data\n\n# Specify the URL to your image\nimage_url=\"https://upload.wikimedia.org/wikipedia/commons/e/ef/MandibularAnteriorCalculus.JPG\"\ninput_shape = (299, 299)  # Target size for the model\n\n# Load the original image and preprocess it\noriginal_image, input_data = preprocess_image_from_url(image_url, input_shape)\n\n# Model inference (assuming the interpreter and labels are already set up)\ninput_data = input_data.astype(input_details[0]['dtype'])  # Match model's expected dtype\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\noutput = interpreter.get_tensor(output_details[0]['index'])\n\n# Apply softmax to get probabilities\nprobabilities = tf.nn.softmax(output).numpy()\npredicted_label_index = np.argmax(probabilities)\npredicted_label = labels[predicted_label_index]\npredicted_probability = probabilities[0][predicted_label_index]\n\n# Display the original image with the prediction\nplt.imshow(original_image)\nplt.title(f\"Prediction: {predicted_label} ({predicted_probability:.2f})\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels=['hp','cr','ht','td','gv','uc','cal']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Load and preprocess the image from a local file path\ndef preprocess_image_from_path(image_path, target_size):\n    # Open the image file\n    img = Image.open(image_path).convert(\"RGB\")\n    # Resize the image\n    img = img.resize(target_size)\n    # Convert to a numpy array with FLOAT32 type and scale to [0, 1]\n    img_array = np.array(img).astype(np.float32) / 255.0\n    # Reorder dimensions to [batch, channels, height, width]\n    img_array = np.transpose(img_array, (2, 0, 1))  # Convert to [3, 299, 299]\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    return img, img_array  # Return both the original image and preprocessed data\n\n# Specify the path to your image\nimage_path=\"/kaggle/input/gigi-wisnu/5c234275-9cf9-41f2-9ec0-b0265066cf7c.jpeg\"\ninput_shape = (299, 299)  # Target size for the model\n\n# Load the original image and preprocess it\noriginal_image, input_data = preprocess_image_from_path(image_path, input_shape)\n\n# Model inference (assuming the interpreter and labels are already set up)\ninput_data = input_data.astype(input_details[0]['dtype'])  # Match model's expected dtype\ninterpreter.set_tensor(input_details[0]['index'], input_data)\ninterpreter.invoke()\noutput = interpreter.get_tensor(output_details[0]['index'])\n\n# Apply softmax to get probabilities\nprobabilities = tf.nn.softmax(output).numpy()\npredicted_label_index = np.argmax(probabilities)\npredicted_label = labels[predicted_label_index]\npredicted_probability = probabilities[0][predicted_label_index]\n\n# Display the original image with the prediction\nplt.imshow(original_image)\nplt.title(f\"Prediction: {predicted_label} ({predicted_probability:.2f})\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probabilities","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_label_index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probabilities","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Input data shape:\", input_data.shape)  # Should print (1, 299, 299, 3)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nlogits = np.array([[-2.7686172, 1.1058136, -8.277714, 0.58694863, 1.1938576, -3.8399513]])\nprobabilities = np.exp(logits) / np.sum(np.exp(logits))\nprint(\"Class probabilities:\", probabilities)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = list(categories)  # Convert to a list if it's a Pandas Index or other non-serializable type\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}